---
title: 'Trawl Summary'
author: "Jim Junker"
date: "`r format(Sys.time(), '%d %B, %Y')`"
knit: (function(inputFile, encoding) { 
      out_dir <- '../docs';
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), out_dir, 'trawl_summary.html')) })
output: 
  html_document:
      keep_md: true
      toc: true
      toc_float: true
      toc_depth: 3
      numbered_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(vegan)
library(betapart)
library(lubridate)
library(viridis)

'%ni%' <- Negate('%in%')

TB_trawl_data <- readRDS("../data/TB_trawl_data.rds")

```

#TERREBONNE BAY TRAWL ANALYSIS SUMMARY {.unlisted .unnumbered}

*insert terrebonne image here*

This document summarizes trawl catch data within Terrebonne Bay, Louisiana (*lat. long.*) conducted by the Education Department of the Louisiana Universities Marine Consortium (LUMCON) from `r paste0(unique(min(TB_trawl_data$year))," - ",unique(max(TB_trawl_data$year)))`.

# Metadata summary

## Sampling locations map
*insert sampling locations, i.e. trawls start and stop, here*

# Environmental Data

A suite of environmental data have been collected through <a href="https://lumcon.edu/environmental-monitoring/" target="_blank">LUMCON's environmental monitoring program</a> over the course of the study period. These variables include:

- Water Temperature
- Salinity
- Specific conductivity
- Dissolved Oxygen

```{r import environmental data, include = FALSE}

  temp_paths <- list.files(path = "../data/", "*temp_*", full.names = TRUE)
  temp_files <- lapply(temp_paths, read_csv, skip = 1,
                       col_types = cols(TS = col_datetime(format = "%m/%d/%Y %H:%M")))
  
  roundUP <- function(x,to=10){
    to*(x%/%to + as.logical(x%%to))
  }
  
  tempF_to_C <- function(F){(5/9)*(F-32)}
  
  temp_df <- bind_rows(temp_files) %>%
    rename(datetime = 'TS', temp_F = 'F') %>%
    mutate(yday = yday(datetime))
  
  do_paths <- list.files(path = "../data/", "*DO_*", full.names = TRUE)
  do_files <- lapply(do_paths, read_csv, skip = 1,
                     col_types = cols(TS = col_datetime(format = "%m/%d/%Y %H:%M")))
  
  do_df <- bind_rows(do_files) %>%
    rename(datetime = 'TS', do_mg_L = 'mg L') %>%
    mutate(yday = yday(datetime))
  
  hydro_paths <- list.files(path = "../data/", "hydro{1}.*.csv", full.names= TRUE)
  hydro_files <- lapply(hydro_paths, read_csv, col_type = cols(ArrayID = col_skip(), Year = col_skip(), JDay= col_skip(),
                                                               X4 = col_skip(), X5 = col_skip(), X6 = col_skip(), Time = col_skip(), X8 = col_skip(), `Date/Time` = col_character(),
                                                               DO = col_skip(), Value4 = col_double(), Depth = col_skip(), `Depth feet` = col_skip()))
  hydro_df <- bind_rows(hydro_files) %>%
    rename(datetime = 'Date/Time', temp_C = 'Temp', temp_F = 'Water Temp F', spCon_uS_cm = 'Value4', sal_psu = 'Sal') %>%
    mutate(datetime = parse_date_time(datetime, orders = c("%m/%d/%Y %H:%M", "%m/%d/%y %H:%M")),
           yday = yday(datetime))
env_long <- hydro_df %>% select(-yday, -temp_F) %>% bind_rows(temp_df %>% mutate(temp_C = tempF_to_C(temp_F)) %>% select(-yday, -temp_F)) %>%
  full_join(do_df %>% select(-yday)) %>%
  # full_join(temp_df %>% mutate(temp_C = tempF_to_C(temp_F))%>% select(-yday, - temp_F), all = TRUE) %>%
  pivot_longer(cols = temp_C:do_mg_L, names_to = "env_var", values_to = "value")

```

These data vary in coverage and are being updated:

`r knitr::include_graphics("../figures/env_facet_plot.png")`

More data will be necessary to fully complete analyses, but this shows the emerging environmental picture.

# Biological Data

The education department has been conducting trawl surveys pretty consistently since 2007. These sampling dates are pretty evenly distributed throughout the year

## Sampling Events

```{r sampling events, include = TRUE, echo = FALSE}

TB_trawl_samplings <- TB_trawl_data %>% select(Date) %>%
  group_by(Date) %>% distinct %>% ungroup %>%
  mutate(Date = as.Date(Date), 
         Date_num = as.numeric(Date))

date_breaks = as.numeric(as.Date(paste0(seq(2007,2020, by = 1),"-01-01")))
date_labels = year(as.Date(date_breaks, origin = "1970-01-01"))

ggplot(TB_trawl_samplings, aes(x = Date, y = 0))+ geom_vline(aes(xintercept = as.numeric(ymd(Date)))) +
  scale_x_continuous(breaks = date_breaks, labels = date_labels) + theme_minimal() +
  theme(axis.title = element_blank()) 

```

There are a lot of sampling trawls over the past decade (n = 359) and they are spread pretty consistently over the year, but with some periods of heavy sampling: 

```{r month sampling events, include=TRUE, echo=FALSE}


TB_month_hist <- TB_trawl_samplings %>%
  mutate(month_num = lubridate::month(Date), 
         month_name = lubridate::month(Date, label = TRUE)) 

  ggplot(TB_month_hist, aes(month_num)) + geom_bar(width = 1) +
    scale_x_continuous(breaks = seq(1,12, by = 1), labels = lubridate::month(seq(1,12,by = 1), label = TRUE)) +
    theme_minimal() +
    theme(axis.title = element_blank())
  
```

## Species sampling

Over the full dataset we can estimate the species accumulation by # of trawls

```{r full richness curve, include = TRUE, echo=FALSE}

# Full species accumulation curve (SAC)

##create taxa by site matrix
TB_trawl_commonsite <- TB_trawl_data %>%
  select(year, month, date_id, Common_name) %>%
  group_by(date_id, Common_name) %>%
  distinct() %>% 
  mutate(pres = 1) %>%
  pivot_wider(names_from = Common_name, values_from = pres, values_fill = list(pres = 0)) %>%
  ungroup()

sp1 <- vegan::specaccum(TB_trawl_commonsite %>% select(-year, -month, -date_id))
spp_mod.df <- data.frame(trawls = sp1[["sites"]], richness = sp1[["richness"]], richness_sd = sp1[["sd"]])

ggplot(spp_mod.df, aes(x = trawls, y = richness)) + geom_path(size = 2, colour = 'red') +
  geom_ribbon(aes(x = trawls, ymin = (richness - 1.96*richness_sd), ymax = (richness + 1.96*richness_sd)), colour = "red", fill = "red", alpha = 0.5) +
  scale_y_continuous(name = expression(Sigma~"species"), breaks = seq(0,roundUP(max(spp_mod.df$richness), to = 10), by = 10), labels = seq(0,roundUP(max(spp_mod.df$richness), to = 10), by = 10)) +
  scale_x_continuous(name = "Trawls", breaks = seq(0,roundUP(max(spp_mod.df$trawls), to = 10), by = 20)) +
  theme_minimal()

```

And by the trawls within each year to get at the differences in sampling effort (assuming each trawl is the same). This suggests there are certain years (or trawl locations):

```{r, include = TRUE, echo = FALSE, warning=FALSE}
## SAC for each year
TB_trawl_commondate <- TB_trawl_data %>%
  select(year, Date, Common_name) %>%
  group_by(Date, Common_name) %>%
  distinct() %>% 
  mutate(pres = 1) %>%
  pivot_wider(names_from = Common_name, values_from = pres, values_fill = list(pres = 0)) %>%
  ungroup()


TB_trawl_taxasite_yr <- TB_trawl_commondate %>%
  group_split(year) %>%
  map(., ~.x %>%  select(-year, -Date) %>% vegan::specaccum(.) %>%
       rlist::list.remove(names(.) %ni% c("sites","richness","sd")) %>%
        bind_cols) %>% 
  map2(., TB_trawl_commondate %>% group_split(year), ~..1 %>% 
         mutate(year = ..2 %>% select(year) %>% unlist %>% as.factor)) %>%
  bind_rows

ggplot(TB_trawl_taxasite_yr, aes(x = sites, y = richness, group = year, colour = year)) +
  geom_path(size = 1.5) +# geom_ribbon(aes(x = sites, ymin = (richness - 1.96*sd), ymax = (richness + 1.96*sd), fill = year), alpha = 0.2) +
  scale_y_continuous(name = expression(Sigma~"species"),breaks = seq(0, roundUP(max(TB_trawl_taxasite_yr$richness), to = 10), by = 10), labels = seq(0, roundUP(max(TB_trawl_taxasite_yr$richness), to = 10), by = 10)) +
  scale_x_continuous(name = "Trawls", breaks = seq(0, roundUP(max(TB_trawl_taxasite_yr$sites), to = 10), by = 5)) +
  scale_colour_viridis(discrete = TRUE) + 
  scale_fill_viridis(discrete = TRUE) +
  theme_minimal()

```

Squinting this suggests that, generally, there might be increasing # of species more broadly. 